{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-21bfcf8d2e40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = '../Data/Use/Train/'\n",
    "os.listdir(DIR_TRAIN)\n",
    "print('# Species in train set:',len(os.listdir(DIR_TRAIN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = train_datagen.flow_from_directory(DIR_TRAIN,\n",
    "                                                target_size=(224,224), \n",
    "                                                color_mode='rgb', \n",
    "                                                class_mode='categorical', \n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([train_datagen.next()[0] for i in range(train_datagen.__len__())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CASPIAN_TERN = X[0:100]\n",
    "D_ARNAUDS_BARBET = X[100:200]\n",
    "DARK_EYED_JUNCO = X[200:300]\n",
    "HOUSE_FINCH = X[300:400]\n",
    "OVENBIRD = X[400:500]\n",
    "OYSTER_CATCHER = X[500:600]\n",
    "RED_TAILED_HAWK = X[600:700]\n",
    "SWINHOES_PHEASENT = X[700:800]\n",
    "VIOLET_GREEN_SWALLOW = X[800:900]\n",
    "WOOD_DUCK = X[900:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Autoencoder training (Spoiler: It doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_training(list_of_data):\n",
    "\n",
    "    lis = []\n",
    "    lis2 = []\n",
    "\n",
    "    for x in list_of_data:\n",
    "        # Save the n-1 images to the list\n",
    "        for i in range(len(x)-1):\n",
    "            lis.append(x[i+1])\n",
    "            lis2.append(x[i])\n",
    "    \n",
    "    tup = (lis, lis2)\n",
    "\n",
    "    return tup\n",
    "\n",
    "tup = k_fold_training([WOOD_DUCK, CASPIAN_TERN, D_ARNAUDS_BARBET, DARK_EYED_JUNCO, HOUSE_FINCH, OVENBIRD, OYSTER_CATCHER, RED_TAILED_HAWK, SWINHOES_PHEASENT, VIOLET_GREEN_SWALLOW])\n",
    "\n",
    "print(np.shape(tup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tup[0][350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tup[1][350])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tup)\n",
    "\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.float32)))\n",
    "dataset = dataset.map(lambda x, y: (tf.expand_dims(x, 0), tf.expand_dims(y, 0)))\n",
    "\n",
    "dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expe = dataset.shuffle(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(tf.squeeze(expe.as_numpy_iterator().next()[0],[0]))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tf.squeeze(expe.as_numpy_iterator().next()[1],[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare both datasets \n",
    "\n",
    "normal_dataset = dataset.prefetch(20)\n",
    "\n",
    "dataset_with_shuffle = expe.prefetch(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = [\n",
    "            tf.keras.layers.InputLayer(input_shape=(None,224,224,3)),\n",
    "            tf.keras.layers.Conv2D(filters=4,kernel_size=3,strides=2,padding='valid', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=8,kernel_size=3,strides=2,padding='valid', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=16,kernel_size=3,strides=2,padding='valid', activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim*latent_dim*3)\n",
    "        ]\n",
    "\n",
    "        self.decoder = [\n",
    "            tf.keras.layers.Reshape(target_shape=(latent_dim,latent_dim,3)),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=16,kernel_size=2,strides=2,padding='valid', activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=8,kernel_size=2,strides=2,padding='valid', activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=4,kernel_size=2,strides=2,padding='valid', activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=2, strides=2, padding='valid', activation='sigmoid'),\n",
    "            tf.keras.layers.Reshape(target_shape=(224,224,3))\n",
    "        ]\n",
    "\n",
    "    def encode(self, x):\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input):\n",
    "        x = self.encode(input)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = autoencoder(latent_dim=14)\n",
    "\n",
    "auto.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "auto.build(input_shape=(None,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird = DARK_EYED_JUNCO\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    image_to_predict = tf.expand_dims(bird[i], 0).numpy()\n",
    "    embeddings = auto.encode(image_to_predict).numpy()  \n",
    "    plt.imshow(embeddings.reshape(14,14,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Autoencode (Same Inputs as Targets) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto2 = autoencoder(latent_dim=14)\n",
    "\n",
    "auto2.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "auto2.build(input_shape=(None,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto2.fit(X, X, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56e98236f8c636bf46699ec7acbcf4f82fa7d2f8d04c118bb47e5affabcc0765"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('cuda2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
