{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNeXt implementation\n",
    "This is an implementation of the *ConvNeXt* architecture as proposed by *FAIR*.<br>\n",
    "The original paper can be found here: https://github.com/facebookresearch/ConvNeXt<br>\n",
    "The implementation below is inspired by: https://github.com/bamps53/convnext-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import (Conv2D, Dense, DepthwiseConv2D,\n",
    "                                     GlobalAveragePooling2D, Layer,\n",
    "                                     LayerNormalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "DIR_BASE = r'C:\\Users\\jch\\Tensorflow\\Project\\Data\\Samples'\n",
    "DIR_TRAIN = r'C:\\Users\\jch\\Tensorflow\\Project\\Data\\Use\\Train'\n",
    "DIR_TEST = r'C:\\Users\\jch\\Tensorflow\\Project\\Data\\Use\\Test'\n",
    "DIR_VALID = r'C:\\Users\\jch\\Tensorflow\\Project\\Data\\Use\\Valid'\n",
    "\n",
    "#AUGMENTED_TRAIN = r'C:\\Users\\jch\\Tensorflow\\Project\\Data\\Use\\Preprocessed\\Augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CASPIAN TERN',\n",
       " 'D-ARNAUDS BARBET',\n",
       " 'DARK EYED JUNCO',\n",
       " 'HOUSE FINCH',\n",
       " 'OVENBIRD',\n",
       " 'OYSTER CATCHER',\n",
       " 'RED TAILED HAWK',\n",
       " 'SWINHOES PHEASANT',\n",
       " 'VIOLET GREEN SWALLOW',\n",
       " 'WOOD DUCK']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show classes\n",
    "os.listdir(DIR_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n",
      "Found 50 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = train_datagen.flow_from_directory(DIR_TRAIN,\n",
    "                                                target_size=(224,224), \n",
    "                                                color_mode='rgb', \n",
    "                                                class_mode='categorical', \n",
    "                                                batch_size=16,\n",
    "                                                shuffle=True)\n",
    "\n",
    "valid_datagen = valid_datagen.flow_from_directory(DIR_VALID,\n",
    "                                                target_size=(224,224), \n",
    "                                                color_mode='rgb', \n",
    "                                                class_mode='categorical', \n",
    "                                                batch_size=16,\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first augmentation function: mix-up\n",
    "# as proposed by FAIR: https://github.com/facebookresearch/mixup-cifar10\n",
    "# inspired by: https://keras.io/examples/vision/mixup/\n",
    "\n",
    "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
    "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
    "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
    "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
    "\n",
    "\n",
    "def mix_up(ds_one, ds_two, alpha=0.2):\n",
    "    '''Returns mixed inputs & pairs of targets'''\n",
    "\n",
    "    # unpack datasets\n",
    "    images_one, labels_one = ds_one\n",
    "    images_two, labels_two = ds_two\n",
    "    batch_size = tf.shape(images_one)[0]\n",
    "\n",
    "    # sample lambda from beta distribution and reshape\n",
    "    lam = sample_beta_distribution(batch_size, alpha, alpha)\n",
    "    x_lam = tf.reshape(lam, (batch_size, 1, 1, 1))\n",
    "    y_lam = tf.reshape(lam, (batch_size, 1))\n",
    "\n",
    "    # perform mixup on both images and labels by combining a pair of images/labels\n",
    "    # (one from each dataset) into one image/label pair\n",
    "    images = images_one * x_lam + images_two * (1 - x_lam)\n",
    "    labels = labels_one * y_lam + labels_two * (1 - y_lam)\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE AUGMENTATION... to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jch\\Tensorflow\\Project\\Code\\New topic\\convNeXt.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/New%20topic/convNeXt.ipynb#ch0000023?line=0'>1</a>\u001b[0m \u001b[39m# First create the new dataset using our `mix_up` utility\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/New%20topic/convNeXt.ipynb#ch0000023?line=1'>2</a>\u001b[0m train_ds_mu \u001b[39m=\u001b[39m train_ds\u001b[39m.\u001b[39mmap(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/New%20topic/convNeXt.ipynb#ch0000023?line=2'>3</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m ds_one, ds_two: mix_up(ds_one, ds_two, alpha\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m), num_parallel_calls\u001b[39m=\u001b[39mAUTO\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/New%20topic/convNeXt.ipynb#ch0000023?line=3'>4</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/New%20topic/convNeXt.ipynb#ch0000023?line=5'>6</a>\u001b[0m \u001b[39m# Let's preview 9 samples from the dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/New%20topic/convNeXt.ipynb#ch0000023?line=6'>7</a>\u001b[0m sample_images, sample_labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_ds_mu))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "# First create the new dataset using our `mix_up` utility\n",
    "train_ds_mu = train_ds.map(\n",
    "    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n",
    ")\n",
    "\n",
    "# Let's preview 9 samples from the dataset\n",
    "sample_images, sample_labels = next(iter(train_ds_mu))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().squeeze())\n",
    "    print(label.numpy().tolist())\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 888 images belonging to 222 classes.\n",
      "Found 221 images belonging to 222 classes.\n"
     ]
    }
   ],
   "source": [
    "# IGNORE THS BLOCK FOR A MOMENT...\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "training_generator = datagen.flow_from_directory(DIR_BASE,\n",
    "                                                target_size=(224,224), \n",
    "                                                color_mode='rgb', \n",
    "                                                class_mode='categorical', \n",
    "                                                batch_size=16,\n",
    "                                                shuffle=True,\n",
    "                                                subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(DIR_BASE,\n",
    "                                                target_size=(224,224), \n",
    "                                                color_mode='rgb', \n",
    "                                                class_mode='categorical', \n",
    "                                                batch_size=16,\n",
    "                                                shuffle=True,\n",
    "                                                subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop path function / class for randomly dropping entire blocks (\"stochastic depth\")\n",
    "\n",
    "def drop_path(inputs, drop_prob, is_training):\n",
    "    # copied from https://github.com/bamps53/convnext-tf/blob/master/models/convnext_tf.py who borrowed from https://github.com/rishigami/Swin-Transformer-TF/blob/main/swintransformer/model.py\n",
    "    if (not is_training) or (drop_prob == 0.):\n",
    "        return inputs\n",
    "\n",
    "    # Compute keep_prob\n",
    "    keep_prob = 1.0 - drop_prob\n",
    "\n",
    "    # Compute drop_connect tensor\n",
    "    random_tensor = keep_prob\n",
    "    shape = (tf.shape(inputs)[0],) + (1,) * \\\n",
    "        (len(tf.shape(inputs)) - 1)\n",
    "    random_tensor += tf.random.uniform(shape, dtype=inputs.dtype)\n",
    "    binary_tensor = tf.floor(random_tensor)\n",
    "    output = tf.math.divide(inputs, keep_prob) * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class DropPath(tf.keras.layers.Layer):\n",
    "    # copied from https://github.com/bamps53/convnext-tf/blob/master/models/convnext_tf.py who borrowed from https://github.com/rishigami/Swin-Transformer-TF/blob/main/swintransformer/model.py\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        return drop_path(x, self.drop_prob, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual block class\n",
    "\n",
    "class Block(Layer):\n",
    "    # copied from https://github.com/bamps53/convnext-tf/blob/master/models/convnext_tf.py\n",
    "\n",
    "    \"\"\" ConvNeXt Block (permutation from Pytorch to TF standards)\n",
    "    DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    . N = number of images in the batch\n",
    "    . H = height of the image\n",
    "    . W = width of the image\n",
    "    . C = number of channels of the image (3 for RGB)\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6, prefix=''):\n",
    "        super().__init__()\n",
    "        self.dwconv = DepthwiseConv2D(\n",
    "            kernel_size=7, padding='same')  # depthwise conv\n",
    "        self.norm = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.pwconv1 = Dense(4 * dim)\n",
    "        self.act = tf.keras.activations.gelu\n",
    "        self.pwconv2 = Dense(dim)\n",
    "        self.drop_path = DropPath(drop_path)\n",
    "        self.dim = dim\n",
    "        self.layer_scale_init_value = layer_scale_init_value\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gamma = tf.Variable(\n",
    "            initial_value=self.layer_scale_init_value * tf.ones((self.dim)),\n",
    "            trainable=True,\n",
    "            name=f'{self.prefix}/gamma')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        # x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        # x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXt(tf.keras.Model):\n",
    "    # copied from https://github.com/bamps53/convnext-tf/blob/master/models/convnext_tf.py\n",
    "\n",
    "    r\"\"\" ConvNeXt\n",
    "        A Tensorflow keras impl of : `A ConvNet for the 2020s`  -\n",
    "          https://arxiv.org/pdf/2201.03545.pdf\n",
    "    Args:\n",
    "        num_classes (int): Number of classes for classification head\n",
    "        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
    "        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
    "        include_top (bool): whether to add head or just use it as feature extractor. Default: True\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10,\n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], include_top=True,\n",
    "                 drop_path_rate=0., layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.include_top = include_top\n",
    "        self.downsample_layers = []  # stem and 3 intermediate downsampling conv layers\n",
    "        stem = tf.keras.Sequential([\n",
    "            Conv2D(dims[0], kernel_size=4, strides=4, padding='same'),\n",
    "            LayerNormalization(epsilon=1e-6)]\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = tf.keras.Sequential([\n",
    "                LayerNormalization(epsilon=1e-6),\n",
    "                Conv2D(dims[i+1], kernel_size=2, strides=2, padding='same')]\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = []  # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates = [x for x in np.linspace(0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = tf.keras.Sequential(\n",
    "                [Block(dim=dims[i], drop_path=dp_rates[cur + j],\n",
    "                       layer_scale_init_value=layer_scale_init_value, prefix=f'block{i}') for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        if self.include_top:\n",
    "            self.avg = GlobalAveragePooling2D()\n",
    "            self.norm = LayerNormalization(epsilon=1e-6)  # final norm layer\n",
    "            self.head = Dense(num_classes)\n",
    "        else:\n",
    "            self.avg = None\n",
    "            self.norm = None\n",
    "            self.head = None\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return x\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        if self.include_top:\n",
    "            x = self.avg(x)\n",
    "            x = self.norm(x)\n",
    "            x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_ne_xt_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_88 (Sequential)   (None, 56, 56, 16)        816       \n",
      "_________________________________________________________________\n",
      "sequential_89 (Sequential)   (None, 28, 28, 32)        2112      \n",
      "_________________________________________________________________\n",
      "sequential_90 (Sequential)   (None, 14, 14, 64)        8320      \n",
      "_________________________________________________________________\n",
      "sequential_91 (Sequential)   (None, 7, 7, 128)         33024     \n",
      "_________________________________________________________________\n",
      "sequential_92 (Sequential)   (None, 56, 56, 16)        8928      \n",
      "_________________________________________________________________\n",
      "sequential_93 (Sequential)   (None, 28, 28, 32)        30144     \n",
      "_________________________________________________________________\n",
      "sequential_94 (Sequential)   (None, 14, 14, 64)        328320    \n",
      "_________________________________________________________________\n",
      "sequential_95 (Sequential)   (None, 7, 7, 128)         415488    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  multiple                  0         \n",
      "_________________________________________________________________\n",
      "layer_normalization_275 (Lay multiple                  256       \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 828,698\n",
      "Trainable params: 828,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The models default variables seem to work well with the ImageNet 1000 dataset, but not with 10 classes (our case)\n",
    "\n",
    "convnext = ConvNeXt(num_classes=10, depths=[3, 3, 9, 3], dims=[16, 32, 64, 128], include_top=True, drop_path_rate=0.3)\n",
    "\n",
    "convnext.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "convnext.build(input_shape=(None, 224, 224, 3))\n",
    "convnext.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 39s 187ms/step - loss: 7.4613 - accuracy: 0.1065 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 6.8019 - accuracy: 0.1015 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 21s 167ms/step - loss: 6.7213 - accuracy: 0.1015 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 6.6326 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 6.8905 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 21s 171ms/step - loss: 6.8744 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 6.8663 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 21s 171ms/step - loss: 6.8744 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 6.8744 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 6.7857 - accuracy: 0.1000 - val_loss: 6.4472 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2175d6ecb00>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnext.fit(augmented_train_datagen, epochs=10, validation_data=valid_datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premade Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model and configure depth and dimensions\n",
    "# copied from https://github.com/bamps53/convnext-tf/blob/master/models/convnext_tf.py\n",
    "\n",
    "model_url = {\n",
    "    \"convnext_tiny_224\": \"https://github.com/bamps53/convnext-tf/releases/download/v0.1/convnext_tiny_1k_224_ema.h5\"\n",
    "}\n",
    "\n",
    "model_configs = dict(\n",
    "    convnext_tiny=dict(\n",
    "        depths=[3, 3, 9, 3],\n",
    "        dims=[96, 192, 384, 768]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build model (we confine the model to the most basic pre-trained model since we have less classes)\n",
    "# copied from https://github.com/bamps53/convnext-tf/blob/master/models/convnext_tf.py\n",
    "\n",
    "def create_model(model_name='convnext_tiny_1k', input_shape=(224, 224), num_classes=10, include_top=True, pretrained=True, use_tpu=False, **kwargs):\n",
    "    cfg = model_configs['_'.join(model_name.split('_')[:2])]\n",
    "    print(cfg)\n",
    "    net = ConvNeXt(num_classes, cfg['depths'], cfg['dims'], include_top, **kwargs)\n",
    "    net(tf.keras.Input(shape=(*input_shape, 3)))\n",
    "    if pretrained is True:\n",
    "        url = model_url\n",
    "        pretrained_ckpt = tf.keras.utils.get_file(\n",
    "            f'{model_name}.h5', url, untar=False)\n",
    "        if use_tpu:\n",
    "            load_locally = tf.saved_model.LoadOptions(\n",
    "                experimental_io_device='/job:localhost')\n",
    "            net.load_weights(\n",
    "                pretrained_ckpt, options=load_locally, skip_mismatch=True)\n",
    "        else:\n",
    "            net.load_weights(pretrained_ckpt, skip_mismatch=True, by_name=True)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depths': [3, 3, 9, 3], 'dims': [96, 192, 384, 768]}\n",
      "Downloading data from {'convnext_tiny_224': 'https://github.com/bamps53/convnext-tf/releases/download/v0.1/convnext_tiny_1k_224_ema.h5'}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'timeout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jch\\Tensorflow\\Project\\Code\\Old topic\\convNeXt.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39m# intiliase model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000012?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m3\u001b[39m), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000012?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m create_model()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000012?line=4'>5</a>\u001b[0m out \u001b[39m=\u001b[39m model(x)\n",
      "\u001b[1;32mc:\\Users\\jch\\Tensorflow\\Project\\Code\\Old topic\\convNeXt.ipynb Cell 10'\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(model_name, input_shape, num_classes, include_top, pretrained, use_tpu, **kwargs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m pretrained \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=9'>10</a>\u001b[0m     url \u001b[39m=\u001b[39m model_url\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=10'>11</a>\u001b[0m     pretrained_ckpt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mget_file(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=11'>12</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, url, untar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m use_tpu:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=13'>14</a>\u001b[0m         load_locally \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mLoadOptions(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jch/Tensorflow/Project/Code/Old%20topic/convNeXt.ipynb#ch0000010?line=14'>15</a>\u001b[0m             experimental_io_device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\data_utils.py:276\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=273'>274</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=274'>275</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=275'>276</a>\u001b[0m     urlretrieve(origin, fpath, dl_progress)\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=276'>277</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=277'>278</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(error_msg\u001b[39m.\u001b[39mformat(origin, e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmsg))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\data_utils.py:82\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=78'>79</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=79'>80</a>\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=81'>82</a>\u001b[0m response \u001b[39m=\u001b[39m urlopen(url, data)\n\u001b[0;32m     <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=82'>83</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fd:\n\u001b[0;32m     <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/site-packages/keras/utils/data_utils.py?line=83'>84</a>\u001b[0m   \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_read(response, reporthook\u001b[39m=\u001b[39mreporthook):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\urllib\\request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=219'>220</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=220'>221</a>\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=221'>222</a>\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=511'>512</a>\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=512'>513</a>\u001b[0m         req\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n\u001b[1;32m--> <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=514'>515</a>\u001b[0m req\u001b[39m.\u001b[39mtimeout \u001b[39m=\u001b[39m timeout\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=515'>516</a>\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m    <a href='file:///c%3A/Users/jch/anaconda3/envs/tf/lib/urllib/request.py?line=517'>518</a>\u001b[0m \u001b[39m# pre-process request\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'timeout'"
     ]
    }
   ],
   "source": [
    "# intiliase model\n",
    "x = tf.zeros((1, 224, 224, 3), dtype=tf.float32)\n",
    "\n",
    "model = create_model()\n",
    "out = model(x) # (1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19c85bbfe7effb49447aeb64fbca2aee00ed9e5c40f48ae198220994744fa986"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
